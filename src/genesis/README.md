# Genesis Core Engine (`src/genesis`)

The `genesis` package is the beating heart of the Arbiter project. It contains the complete source code for training, evaluating, and managing the Genesis language models.

This directory has been professionalized to follow modern Python package standards, ensuring modularity, type safety, and clear separation of concerns.

## ğŸ—ï¸ Architecture Overview

The system is designed around a modular **Trainer-Callback** architecture:
-   **Trainer (`training/`)**: Handles the training loop, optimization, and state management.
-   **Models (`models/`)**: Pure PyTorch implementations of the Llama architecture with FlashAttention.
-   **Pipelines (`pipelines/`)**: High-level orchestration scripts for end-to-end workflows.
-   **Utils (`utils/`)**: Shared infrastructure for logging, configuration, and checkpoints.

## ğŸ“‚ Directory Structure

```text
src/genesis/
â”œâ”€â”€ models/                 # Neural network architectures
â”‚   â”œâ”€â”€ llama/              # Core Transformer implementation (FlashAttention)
â”‚   â””â”€â”€ multi_task.py       # Multi-task heads wrapper
â”œâ”€â”€ datasets/               # Data ingestion
â”‚   â””â”€â”€ multi_task.py       # Weighted sampling & data loading
â”œâ”€â”€ training/               # Training Loop & Logic
â”‚   â”œâ”€â”€ trainer.py          # Modular GenesisTrainer class
â”‚   â”œâ”€â”€ scheduler.py        # Learning rate scheduling
â”‚   â””â”€â”€ callbacks/          # Grokking detection & monitoring
â”œâ”€â”€ pipelines/              # Orchestration Workflows
â”‚   â”œâ”€â”€ long_pipeline.py    # Auto-resume long-term training
â”‚   â”œâ”€â”€ quick_eval.py       # < 1 hour checkpoint assessments
â”‚   â””â”€â”€ sweep.py            # Hyperparameter sweep orchestrator
â”œâ”€â”€ evaluation/             # Evaluation Suites
â”‚   â””â”€â”€ procedural.py       # Sub-morphemic alignment tests
â”œâ”€â”€ utils/                  # Shared Utilities
â”‚   â”œâ”€â”€ logger.py           # SQLite + TensorBoard logging
â”‚   â””â”€â”€ config_loader.py    # TOML configuration parser
â”œâ”€â”€ train.py                # ğŸš€ Main Training Entry Point
â””â”€â”€ verify.py               # ğŸ” System Verification Script
```

## ğŸ”‘ Key Components

### 1. Training Engine (`train.py` & `training/`)
The standard entry point for all training jobs is `train.py`. It uses the `GlobalConfig` pattern to load settings from `genesis_config.toml`.
-   **Usage**: Executed via the root `run.py` (Option 1).
-   **Modular Design**: The loop logic is decoupled into `GenesisTrainer`, allowing for easy extension.

### 2. Pipelines (`pipelines/`)
Automated workflows that combine training and evaluation.
-   **Long Pipeline**: Runs for days/weeks, handling crashes and auto-resuming.
-   **Sweep**: Distributed hyperparameter search.
-   **Quick Eval**: Rapid "Go/No-Go" assessment of checkpoints.

### 3. Models (`models/`)
A highly optimized, FlashAttention-enabled implementation of Llama.
-   **`models.llama`**: The base Transformer.
-   **`models.multi_task_wrapper`**: Adds heads for auxiliary tasks (Coherence, Reference, Paraphrase).

### 4. Utilities (`utils/`)
Infrastructure code used across the project.
-   **`ArbiterLogger`**: A unified logger that writes to both a structured SQLite database (for analysis) and TensorBoard (for real-time monitoring).

## ğŸ‘©â€ğŸ’» Development Guidelines

-   **Imports**: Always use relative imports within the package (e.g., `from ..utils import logger`) and absolute imports for verifying scripts.
-   **Configuration**: Do not hardcode parameters. Retrieve them via `get_config_section("section_name")` from `utils/config_loader.py`.
-   **Type Hinting**: All new function signatures must be fully type-hinted.

## ğŸš€ Quick Start
To verify the integrity of the source installation, run:

```bash
python src/genesis/verify.py
```
